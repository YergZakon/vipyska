"""
Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –≤—ã–ø–∏—Å–æ–∫ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ 30+ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç 30 –±–∞–Ω–∫–æ–≤. –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∞.
"""
import streamlit as st
import pandas as pd
import tempfile
import os
import gc
import json
from pathlib import Path
from datetime import datetime
from io import BytesIO

from bank_parser.file_reader import read_excel_file
from bank_parser.detector import detect_parser
from bank_parser.models import Transaction, ParseResult

# Import all parsers so they register themselves
from bank_parser.parsers import (
    standard_18col, narodny, kaspi, otbasy, tengri,
    alatau, tsesnabank, al_hilal, kazkom,
    forte, bank_rbk, eurasian, kassa_nova, delta,
    bcc, kzi, nurbank, freedom, altyn,
    halyk_finance, citibank, bank_razvitiya,
    china_banks, zaman,
)

# --- Page config ---
st.set_page_config(
    page_title="Bank Statement Parser",
    page_icon="üè¶",
    layout="wide",
)

# --- Supported banks ---
SUPPORTED_BANKS = [
    "Kaspi Bank",
    "–ù–∞—Ä–æ–¥–Ω—ã–π –ë–∞–Ω–∫ (Halyk)",
    "–ë–∞–Ω–∫ –¶–µ–Ω—Ç—Ä–ö—Ä–µ–¥–∏—Ç (BCC)",
    "ForteBank",
    "Freedom Bank / Finance",
    "Bank RBK",
    "–ï–≤—Ä–∞–∑–∏–π—Å–∫–∏–π –ë–∞–Ω–∫",
    "–ù—É—Ä–±–∞–Ω–∫",
    "Delta Bank",
    "Home Credit Bank",
    "–û—Ç–±–∞—Å—ã –±–∞–Ω–∫",
    "–í–¢–ë –ë–∞–Ω–∫ (–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω)",
    "–ê–ª—Ç—ã–Ω –ë–∞–Ω–∫",
    "–¢–µ–Ω–≥—Ä–∏ –ë–∞–Ω–∫",
    "–¶–µ—Å–Ω–∞–±–∞–Ω–∫",
    "Al Hilal Islamic Bank",
    "–ö–∞–∑–∫–æ–º–º–µ—Ä—Ü–±–∞–Ω–∫",
    "Halyk Finance",
    "Citibank Kazakhstan",
    "–ë–∞–Ω–∫ –†–∞–∑–≤–∏—Ç–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞",
    "–ë–∞–Ω–∫ –ö–∏—Ç–∞—è –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ",
    "–¢–ü–ë –ö–∏—Ç–∞—è –≤ –ê–ª–º–∞—Ç—ã",
    "Kassa Nova",
    "–ö–ó–ò –ë–∞–Ω–∫",
    "–ó–∞–º–∞–Ω-–ë–∞–Ω–∫",
    "Shinhan Bank",
    "Alatau City",
]

RUSSIAN_HEADERS = Transaction.russian_headers()
FIELD_NAMES = Transaction.field_names()
HEADER_MAP = dict(zip(FIELD_NAMES, RUSSIAN_HEADERS))


def process_uploaded_file(uploaded_file, folder_hint: str = "") -> ParseResult:
    """Process a single uploaded file through our parser pipeline."""
    filename = uploaded_file.name
    ext = Path(filename).suffix.lower()

    result = ParseResult(filepath=filename, source_file=filename)

    if ext not in ('.xlsx', '.xls'):
        result.parse_status = 'skipped'
        result.errors.append(f'Unsupported format: {ext}')
        return result

    # Save to temp file
    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
        tmp.write(uploaded_file.getvalue())
        tmp_path = tmp.name

    try:
        # Read
        sheets = read_excel_file(tmp_path)

        if not sheets or all(s.num_rows == 0 for s in sheets):
            result.parse_status = 'skipped'
            result.warnings.append('Empty file')
            return result

        file_info = {
            'filepath': tmp_path,
            'filename': filename,
            'extension': ext,
            'folder_name': folder_hint,
        }

        # Detect
        parser_cls = detect_parser(sheets, file_info)
        if parser_cls is None:
            result.parse_status = 'failed'
            result.errors.append('No parser detected')
            return result

        # Parse
        parser = parser_cls()
        result = parser.parse(sheets, file_info)
    except Exception as e:
        result.parse_status = 'failed'
        result.errors.append(f'Error: {e}')
    finally:
        gc.collect()
        try:
            os.unlink(tmp_path)
        except (PermissionError, OSError):
            pass

    return result


def transactions_to_df(transactions: list) -> pd.DataFrame:
    """Convert list of Transaction objects to a DataFrame with Russian headers."""
    if not transactions:
        return pd.DataFrame(columns=RUSSIAN_HEADERS)

    rows = [t.to_dict() for t in transactions]
    df = pd.DataFrame(rows)
    df.rename(columns=HEADER_MAP, inplace=True)

    # Reorder to match standard column order
    cols = [c for c in RUSSIAN_HEADERS if c in df.columns]
    df = df[cols]

    return df


# ============================================================
# UI
# ============================================================
st.title("üè¶ –ü–∞—Ä—Å–µ—Ä –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –≤—ã–ø–∏—Å–æ–∫")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –≤—ã–ø–∏—Å–æ–∫ –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏—Ö –±–∞–Ω–∫–æ–≤ ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –±–∞–Ω–∫ –∏ —Ñ–æ—Ä–º–∞—Ç")

# --- Sidebar ---
with st.sidebar:
    st.header("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –±–∞–Ω–∫–∏")
    st.caption(f"–í—Å–µ–≥–æ: {len(SUPPORTED_BANKS)} –±–∞–Ω–∫–æ–≤, 30+ —Ñ–æ—Ä–º–∞—Ç–æ–≤")
    for bank in SUPPORTED_BANKS:
        st.write(f"- {bank}")
    st.divider()
    st.markdown("**–§–æ—Ä–º–∞—Ç—ã:** `.xlsx`, `.xls`")
    st.markdown("**–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:** 20 –ø–æ–ª–µ–π –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")

# --- Session state ---
if 'all_transactions' not in st.session_state:
    st.session_state.all_transactions = []
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []
if 'parse_results' not in st.session_state:
    st.session_state.parse_results = []

# --- Upload ---
st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")

col_upload, col_hint = st.columns([3, 1])
with col_upload:
    uploaded_files = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã –≤—ã–ø–∏—Å–æ–∫",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ",
    )
with col_hint:
    folder_hint = st.text_input(
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞ –±–∞–Ω–∫–∞ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)",
        placeholder="–ù–∞–ø—Ä. Kaspi Bank",
        help="–ï—Å–ª–∏ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç, —É–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–∞–Ω–∫–∞/–ø–∞–ø–∫–∏",
    )

if uploaded_files:
    if st.button("üîÑ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã", type="primary", use_container_width=True):
        all_transactions = []
        processed = []
        results = []

        progress = st.progress(0, text="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞...")

        for i, uf in enumerate(uploaded_files):
            progress.progress(
                (i) / len(uploaded_files),
                text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {uf.name} ({i+1}/{len(uploaded_files)})",
            )

            result = process_uploaded_file(uf, folder_hint)
            results.append(result)
            all_transactions.extend(result.transactions)

            status_icon = {
                'success': '‚úÖ', 'partial': '‚ö†Ô∏è',
                'failed': '‚ùå', 'skipped': '‚è≠Ô∏è',
            }.get(result.parse_status, '‚ùì')

            processed.append({
                '–§–∞–π–ª': uf.name,
                '–ë–∞–Ω–∫': result.bank_detected or '‚Äî',
                '–ü–∞—Ä—Å–µ—Ä': result.parser_used or '‚Äî',
                '–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π': result.total_transactions,
                '–°—Ç–∞—Ç—É—Å': f"{status_icon} {result.parse_status}",
                '–û—à–∏–±–∫–∏': '; '.join(result.errors) if result.errors else '',
            })

        progress.progress(1.0, text="–ì–æ—Ç–æ–≤–æ!")

        st.session_state.all_transactions = all_transactions
        st.session_state.processed_files = processed
        st.session_state.parse_results = results

        success_count = sum(1 for r in results if r.parse_status in ('success', 'partial'))
        st.success(
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {success_count}/{len(uploaded_files)} —Ñ–∞–π–ª–æ–≤, "
            f"–∏–∑–≤–ª–µ—á–µ–Ω–æ {len(all_transactions)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"
        )

# --- Results table ---
if st.session_state.processed_files:
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    df_results = pd.DataFrame(st.session_state.processed_files)
    st.dataframe(df_results, use_container_width=True, hide_index=True)

# --- Stats ---
if st.session_state.all_transactions:
    st.header("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    df = transactions_to_df(st.session_state.all_transactions)

    # Metrics row
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.metric("–í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", f"{len(df):,}")
    with c2:
        if '–°—É–º–º–∞' in df.columns:
            income = pd.to_numeric(
                df.loc[df.get('–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', pd.Series()) == '–ü—Ä–∏—Ö–æ–¥', '–°—É–º–º–∞'],
                errors='coerce'
            ).sum()
            st.metric("–ü—Ä–∏—Ö–æ–¥", f"{income:,.0f} ‚Ç∏")
    with c3:
        if '–°—É–º–º–∞' in df.columns:
            expense = pd.to_numeric(
                df.loc[df.get('–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', pd.Series()) == '–†–∞—Å—Ö–æ–¥', '–°—É–º–º–∞'],
                errors='coerce'
            ).sum()
            st.metric("–†–∞—Å—Ö–æ–¥", f"{expense:,.0f} ‚Ç∏")
    with c4:
        banks_count = df['–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏'].nunique() if '–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏' in df.columns else 0
        st.metric("–ë–∞–Ω–∫–æ–≤", banks_count)

    # Stats by bank
    col_left, col_right = st.columns(2)

    with col_left:
        st.subheader("–ü–æ –±–∞–Ω–∫–∞–º")
        if '–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏' in df.columns and '–°—É–º–º–∞' in df.columns:
            df['_amount'] = pd.to_numeric(df['–°—É–º–º–∞'], errors='coerce')
            bank_stats = df.groupby('–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏').agg(
                –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π=('_amount', 'count'),
                –°—É–º–º–∞=('_amount', 'sum'),
            ).sort_values('–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π', ascending=False).reset_index()
            bank_stats.columns = ['–ë–∞–Ω–∫', '–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π', '–û–±—â–∞—è —Å—É–º–º–∞']
            bank_stats['–û–±—â–∞—è —Å—É–º–º–∞'] = bank_stats['–û–±—â–∞—è —Å—É–º–º–∞'].apply(lambda x: f"{x:,.0f}")
            st.dataframe(bank_stats, use_container_width=True, hide_index=True)
            df.drop(columns=['_amount'], inplace=True, errors='ignore')

    with col_right:
        st.subheader("–ü–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º")
        if '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ' in df.columns and '–°—É–º–º–∞' in df.columns:
            df['_amount'] = pd.to_numeric(df['–°—É–º–º–∞'], errors='coerce')
            dir_stats = df.groupby('–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ').agg(
                –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π=('_amount', 'count'),
                –°—É–º–º–∞=('_amount', 'sum'),
            ).reset_index()
            dir_stats.columns = ['–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π', '–°—É–º–º–∞']
            dir_stats['–°—É–º–º–∞'] = dir_stats['–°—É–º–º–∞'].apply(lambda x: f"{x:,.0f}")
            st.dataframe(dir_stats, use_container_width=True, hide_index=True)
            df.drop(columns=['_amount'], inplace=True, errors='ignore')

    # Date range
    if '–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏' in df.columns:
        dates = pd.to_datetime(df['–î–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏'], errors='coerce').dropna()
        if not dates.empty:
            st.subheader("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö")
            st.write(
                f"–° **{dates.min().strftime('%d.%m.%Y')}** "
                f"–ø–æ **{dates.max().strftime('%d.%m.%Y')}**"
            )

# --- Data preview ---
if st.session_state.all_transactions:
    st.header("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")

    df = transactions_to_df(st.session_state.all_transactions)

    # Filters
    col_f1, col_f2, col_f3 = st.columns(3)

    with col_f1:
        if '–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏' in df.columns:
            banks_list = ['–í—Å–µ'] + sorted(df['–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏'].dropna().unique().tolist())
            selected_bank = st.selectbox("–ë–∞–Ω–∫", banks_list)
            if selected_bank != '–í—Å–µ':
                df = df[df['–ë–∞–Ω–∫ –≤—ã–ø–∏—Å–∫–∏'] == selected_bank]

    with col_f2:
        if '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ' in df.columns:
            dirs_list = ['–í—Å–µ'] + sorted(df['–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ'].dropna().unique().tolist())
            selected_dir = st.selectbox("–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", dirs_list)
            if selected_dir != '–í—Å–µ':
                df = df[df['–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ'] == selected_dir]

    with col_f3:
        num_rows = st.selectbox("–°—Ç—Ä–æ–∫", [25, 50, 100, 500, "–í—Å–µ"], index=0)

    if num_rows == "–í—Å–µ":
        st.dataframe(df, use_container_width=True, hide_index=True)
    else:
        st.dataframe(df.head(num_rows), use_container_width=True, hide_index=True)

    st.caption(
        f"–ü–æ–∫–∞–∑–∞–Ω–æ {min(num_rows if num_rows != '–í—Å–µ' else len(df), len(df))} "
        f"–∏–∑ {len(df)} –∑–∞–ø–∏—Å–µ–π"
    )

# --- Export ---
if st.session_state.all_transactions:
    st.header("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")

    df_export = transactions_to_df(st.session_state.all_transactions)

    col_e1, col_e2, col_e3 = st.columns(3)

    with col_e1:
        # Excel
        output_xlsx = BytesIO()
        with pd.ExcelWriter(output_xlsx, engine='openpyxl') as writer:
            df_export.to_excel(writer, sheet_name='–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏', index=False)
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å Excel",
            data=output_xlsx.getvalue(),
            file_name=f"transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    with col_e2:
        # CSV
        csv_data = df_export.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å CSV",
            data=csv_data,
            file_name=f"transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            use_container_width=True,
        )

    with col_e3:
        # JSON
        json_data = json.dumps(
            [t.to_dict() for t in st.session_state.all_transactions],
            ensure_ascii=False, indent=2,
        )
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å JSON",
            data=json_data,
            file_name=f"transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            use_container_width=True,
        )

# --- Clear ---
if st.session_state.all_transactions:
    st.divider()
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        st.session_state.all_transactions = []
        st.session_state.processed_files = []
        st.session_state.parse_results = []
        st.rerun()

# --- Footer ---
st.divider()
st.caption(
    f"Bank Statement Parser v2.0 | "
    f"{len(SUPPORTED_BANKS)} –±–∞–Ω–∫–æ–≤ | 30+ —Ñ–æ—Ä–º–∞—Ç–æ–≤ | "
    f"80/87 —Ñ–∞–π–ª–æ–≤ (92% –ø–æ–∫—Ä—ã—Ç–∏–µ)"
)
